{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from cs_opl import op_learning\n",
    "from experiment_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kernel_regression.py:237: RuntimeWarning: invalid value encountered in true_divide\n",
      "  B_x = (G_numer * d_fx - G_denom * d_mx) / (G_denom**2)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kernel_regression.py:224: RuntimeWarning: invalid value encountered in true_divide\n",
      "  G = G_numer / G_denom\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kernel_regression.py:236: RuntimeWarning: invalid value encountered in true_divide\n",
      "  B_x = d_mx / f_x - G * d_fx / f_x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 5942.301835143671\n",
      "score 3.039917162584075\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 5942.304079569729\n",
      "score 3.0399065099337528\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 5942.175956652535\n",
      "score 3.0407264719469493\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 5942.122330572993\n",
      "score 3.0412349826294527\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    }
   ],
   "source": [
    "data_name = 'satimage'\n",
    "num_trials = 1\n",
    "sample_size = 300\n",
    "\n",
    "if data_name == 'satimage':\n",
    "    data_name = 'satimage.scale'\n",
    "elif data_name == 'vehicle':\n",
    "    data_name = 'vehicle.scale'\n",
    "\n",
    "alphas = [0.7, 0.4, 0.0]\n",
    "\n",
    "tau_list = np.zeros(num_trials)\n",
    "res_ipw3_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dm_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml2_list = np.zeros((num_trials, len(alphas)))\n",
    "\n",
    "res_ipw3_sn_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml2_sn_list = np.zeros((num_trials, len(alphas)))\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    X, Y, Y_matrix, train_test_split, classes, N, N_train, N_test = data_generation(data_name, sample_size)\n",
    "\n",
    "    X_train, X_test = X[train_test_split], X[~train_test_split]\n",
    "\n",
    "    Y_matrix_train, Y_matrix_test = Y_matrix[train_test_split], Y_matrix[~train_test_split]\n",
    "\n",
    "    for idx_alpha in  range(len(alphas)):    \n",
    "        alpha = alphas[idx_alpha]\n",
    "\n",
    "        pi_behavior, pi_evaluation  = behavior_and_evaluation_policy(X, Y, train_test_split, classes, alpha=alpha)\n",
    "\n",
    "        pi_behavior_train = pi_behavior[train_test_split]\n",
    "        pi_evaluation_train, pi_evaluation_test = pi_evaluation[train_test_split], pi_evaluation[~train_test_split]\n",
    "\n",
    "        tau = true_value(Y_matrix_test, pi_evaluation_test, N_test)\n",
    "        tau_list[trial] = tau\n",
    "\n",
    "        perm = np.random.permutation(N_train)\n",
    "        X_seq_train, Y_matrix_seq_train, pi_behavior_seq_train, pi_evaluation_seq_train = X_train[perm], Y_matrix_train[perm], pi_behavior_train[perm], pi_evaluation_train[perm]\n",
    "\n",
    "        Y_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "        A_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "\n",
    "        for i in range(N_train):\n",
    "            a = np.random.choice(classes, p=pi_behavior_seq_train[i])\n",
    "            Y_historical_matrix[i, a] = Y_matrix_seq_train[i, a]\n",
    "            A_historical_matrix[i, a] = 1\n",
    "            \n",
    "        estimators = op_learning(X_seq_train, A_historical_matrix, Y_historical_matrix, X_test, classes)\n",
    "        \n",
    "        estimators.ipw_est_parameters()\n",
    "        epol_ipw = estimators.ipw_fit(folds=5, algorithm='Ridge', self_norm=False)\n",
    "        epol_ipw_sn = estimators.ipw_fit(folds=5, algorithm='Ridge', self_norm=True)\n",
    "\n",
    "        estimators.dm_est_parameters()\n",
    "        epol_dm = estimators.dm_fit(folds=5, algorithm='Ridge', self_norm=False)\n",
    "        \n",
    "        estimators.dml_est_parameters(folds=5, algorithm='Ridge')\n",
    "        epol_dml = estimators.dml_fit(folds=5, algorithm='Ridge', self_norm=False)\n",
    "        epol_dml_sn = estimators.dml_fit(folds=5, algorithm='Ridge', self_norm=True)\n",
    "\n",
    "        res_ipw3 =  true_value(Y_matrix_test, epol_ipw, N_test)\n",
    "        res_ipw3_sn =  true_value(Y_matrix_test, epol_ipw_sn, N_test)\n",
    "        res_dm =  true_value(Y_matrix_test, epol_dm, N_test)\n",
    "        res_dml2 =  true_value(Y_matrix_test, epol_dml, N_test)\n",
    "        res_dml2_sn =  true_value(Y_matrix_test, epol_dml_sn, N_test)\n",
    "\n",
    "        print('trial', trial)\n",
    "        print('True:', tau)\n",
    "        print('IPW3:', res_ipw3)\n",
    "        print('IPW3_SN:', res_ipw3_sn)\n",
    "        print('DM:', res_dm)\n",
    "        print('DML2:', res_dml2)\n",
    "        print('DML2_SN:', res_dml2_sn)\n",
    "\n",
    "        res_ipw3_list[trial, idx_alpha] = res_ipw3\n",
    "        res_ipw3_sn_list[trial, idx_alpha] = res_ipw3_sn\n",
    "        res_dm_list[trial, idx_alpha] = res_dm\n",
    "        res_dml2_list[trial, idx_alpha] = res_dml2\n",
    "        res_dml2_sn_list[trial, idx_alpha] = res_dml2_sn\n",
    "\n",
    "        np.savetxt(\"exp_results/true_value_%s.csv\"%data_name, tau_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_opl_ipw3_%s.csv\"%data_name, res_ipw3_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_opl_ipw3_sn_%s.csv\"%data_name, res_ipw3_sn_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_opl_dm_%s.csv\"%data_name, res_dm_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_opl_dml2_%s.csv\"%data_name, res_dml2_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_opl_dml2_sn_%s.csv\"%data_name, res_dmlï¼’_sn_list, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = op_learning(X_seq_train, A_historical_matrix, Y_historical_matrix, X_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.ipw_est_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= np.where(estimators.A ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.argmax(estimators.bpol_hat_kernel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(b == c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 2407.5609124271787\n",
      "score 173.83212366984492\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 2407.5618605676373\n",
      "score 173.8322122110753\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 2407.4187763277655\n",
      "score 173.8213224689524\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 2407.4829438586557\n",
      "score 173.82564338621984\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-90d63b809674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_fit\u001b[0;34m(self, folds, num_basis, sigma_list, lda_list, algorithm, self_norm)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mscore0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m-> 1016\u001b[0;31m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    835\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \"\"\"\n\u001b[0;32m--> 756\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_hst_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_estimator\u001b[0;34m(self, x, a, y, bpol, r, beta, lmd, self_norm)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mbeta_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCalcDistanceSquared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_objective_function\u001b[0;34m(self, x, a, y, bpol, r, beta, self_norm)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipw_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators.ipw_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.4131591025766"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 44.80854296996513\n",
      "score 1.308881683828798\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 43.75970334024666\n",
      "score 1.281926501730938\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 37.000672326075744\n",
      "score 1.3933336843048583\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 32.035081210935836\n",
      "score 1.1549892784706297\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 43.38201695690485\n",
      "score 0.028327274226219345\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 42.64913940074736\n",
      "score 0.02774498698525023\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 37.50440384881384\n",
      "score 0.02449441068755044\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n",
      "../cs_opl.py:535: RuntimeWarning: overflow encountered in exp\n",
      "  epol_hst = np.exp(-np.dot(x, beta))\n",
      "../cs_opl.py:536: RuntimeWarning: invalid value encountered in true_divide\n",
      "  epol_hst = (epol_hst.T/np.sum(epol_hst, axis=1)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 nan\n",
      "score nan\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-4621b0864d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ridge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_fit\u001b[0;34m(self, folds, num_basis, sigma_list, lda_list, algorithm, self_norm)\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mscore0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m-> 1016\u001b[0;31m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    835\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \"\"\"\n\u001b[0;32m--> 756\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_hst_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bhv_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hst_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_estimator\u001b[0;34m(self, x, a, y, bpol, r, beta, lmd, self_norm)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mbeta_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipw_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlmd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCalcDistanceSquared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mipw_objective_function\u001b[0;34m(self, x, a, y, bpol, r, beta, self_norm)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0msn_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbpol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0msn_matrix\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepol_hst\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbpol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = estimators.ipw_fit(folds=5, algorithm='Ridge', self_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.ipw_fit(folds=5, algorithm='Ridge', self_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= np.where(estimators.A == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285714285714286"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(b == np.argmax(estimators.bpol_array, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b == np.argmax(estimators.bpol_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5920741597046222\n",
      "score 0.22304838279334344\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5484855666994175\n",
      "score 0.21996685751965783\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4370257580785539\n",
      "score 0.21936581372995897\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.38258719055318824\n",
      "score 0.1960691619150928\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1453535381565161\n",
      "score 0.0998240228390467\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1176025078946443\n",
      "score 0.08761088145672416\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11558404389026423\n",
      "score 0.08667139715272348\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11538739056311095\n",
      "score 0.08657940390012661\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5282926747853551\n",
      "score 0.34780252844829007\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5109027912907325\n",
      "score 0.3399568409582776\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4055612035494752\n",
      "score 0.34152450024979086\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3520824636363296\n",
      "score 0.29516334917349535\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.13652752334001284\n",
      "score 0.1218531906687522\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11333915459848752\n",
      "score 0.10401154383905852\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11156972327647918\n",
      "score 0.10266737187124189\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11139669598380719\n",
      "score 0.10253608878740317\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4669952640284015\n",
      "score 0.5598376835945742\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4536444020528354\n",
      "score 0.5479374514611632\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39621833184501654\n",
      "score 0.5230302456006007\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.30080517793350625\n",
      "score 0.445454783624878\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12596436730438332\n",
      "score 0.14048539803777188\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11013069838605852\n",
      "score 0.11546856899192826\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10883319245221607\n",
      "score 0.11348199984211557\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10870562913990972\n",
      "score 0.11328726563460262\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39710965976676127\n",
      "score 0.41805212964237726\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.396079961879122\n",
      "score 0.41692519179420096\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3884656198223958\n",
      "score 0.40900859533790435\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.334965868974984\n",
      "score 0.35655848867760337\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12478987502715468\n",
      "score 0.16292053667643655\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10340640241501377\n",
      "score 0.14324963682602848\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10178968585387801\n",
      "score 0.14173865512417533\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10163179661348384\n",
      "score 0.14159080385851133\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4899802836787689\n",
      "score 0.45161649531972986\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.47892580349655745\n",
      "score 0.4444898846337131\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.37994757565574855\n",
      "score 0.4400251872869799\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.32715191426173335\n",
      "score 0.36969982092619424\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.13187700208147127\n",
      "score 0.1282170554277957\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11266670154018488\n",
      "score 0.10600801054703018\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11114808929229211\n",
      "score 0.10428776697300235\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11099921460148299\n",
      "score 0.1041194306195582\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5635881019506099\n",
      "score 0.22286923224322044\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5484869187349841\n",
      "score 0.21996710336532868\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4370258072725079\n",
      "score 0.219365849262182\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3825871755589518\n",
      "score 0.19606915506087352\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.14535353802981782\n",
      "score 0.09982402276939147\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11760250789924143\n",
      "score 0.08761088145854126\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11558404388998775\n",
      "score 0.08667139715271259\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11538739056310993\n",
      "score 0.0865794039001261\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5282809984376247\n",
      "score 0.3477919384994353\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5109036637770326\n",
      "score 0.33995855174709066\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.40556122120712096\n",
      "score 0.34152458108981243\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3520824622860344\n",
      "score 0.2951633486948974\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1365275222677335\n",
      "score 0.1218531896682678\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11333915460704265\n",
      "score 0.10401154384663627\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11156972327643608\n",
      "score 0.10266737187029795\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11139669598380705\n",
      "score 0.10253608878740306\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.46696538154341555\n",
      "score 0.559794474152187\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4536457173956152\n",
      "score 0.5479384461546917\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3962223970781258\n",
      "score 0.5230247834768086\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3008051897008194\n",
      "score 0.44545480619077094\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12596436741675351\n",
      "score 0.14048539847176716\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1101306983712559\n",
      "score 0.11546856896645005\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10883319245208137\n",
      "score 0.11348199984285143\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10870562913990978\n",
      "score 0.11328726563460267\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39710824096702735\n",
      "score 0.4180504537604077\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3960800146867093\n",
      "score 0.4169253038803904\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.388465616795696\n",
      "score 0.40900859508747417\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3349658604597687\n",
      "score 0.3565584809798905\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12478987478318442\n",
      "score 0.16292053670435672\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10340640242410976\n",
      "score 0.14324963683618555\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10178968585409946\n",
      "score 0.14173865512648504\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1016317966134826\n",
      "score 0.1415908038585102\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4946383433230932\n",
      "score 0.45122974290138096\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4789275544882864\n",
      "score 0.4444946104234012\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3799475939961945\n",
      "score 0.4400252578315883\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3271519173717991\n",
      "score 0.3696998236786286\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.131877003427078\n",
      "score 0.12821705704179281\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11266670156609912\n",
      "score 0.10600801057069073\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11114808929269412\n",
      "score 0.10428776697469035\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11099921460148598\n",
      "score 0.10411943061956155\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5635982295000443\n",
      "score 0.22287777254382612\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5484878644792979\n",
      "score 0.21998054176646475\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.43702584164451586\n",
      "score 0.21936695670879885\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.38258737707378765\n",
      "score 0.19607290509281383\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1453536713218645\n",
      "score 0.099824667320724\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11760251441497964\n",
      "score 0.0876109211536627\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11558404450197507\n",
      "score 0.08667140096090784\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11538739062390815\n",
      "score 0.08657940427927294\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5310106895740123\n",
      "score 0.3473594774736861\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5109118626178322\n",
      "score 0.33996859318091605\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4055612882894826\n",
      "score 0.3415252415139029\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3520828735514301\n",
      "score 0.29516560914903966\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1365277588390545\n",
      "score 0.12185366049257144\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11333916689839937\n",
      "score 0.10401157212752943\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1115697244381343\n",
      "score 0.10266737457678234\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11139669609931088\n",
      "score 0.10253608905671972\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.46698491688187\n",
      "score 0.5598198770992958\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4536477457813831\n",
      "score 0.5479462775800872\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3962386302128463\n",
      "score 0.5229932960838942\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.30080610632406224\n",
      "score 0.44545371285064717\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12596467536463946\n",
      "score 0.1404856766818791\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11013071664944213\n",
      "score 0.11546858255176434\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1088331941939667\n",
      "score 0.11348200110801976\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10870562931330882\n",
      "score 0.11328726576033098\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39710953797442494\n",
      "score 0.418051956201086\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3960800387704337\n",
      "score 0.4169252563525666\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3884657216433764\n",
      "score 0.40900849878452866\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3349665420985158\n",
      "score 0.3565585293300621\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12479024835820463\n",
      "score 0.16292079512189822\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 0.10340642246564873\n",
      "score 0.1432496496713782\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10178968775375105\n",
      "score 0.14173865633599808\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10163179680237974\n",
      "score 0.14159080397879392\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.48996644681547585\n",
      "score 0.45161110390632925\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.478927804877456\n",
      "score 0.444495064050424\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.37994781838080577\n",
      "score 0.4400237766512656\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.32715293594272604\n",
      "score 0.36969767079655697\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.13187744350696867\n",
      "score 0.12821720377353985\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11266672617861144\n",
      "score 0.10600801396521792\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11114809163040432\n",
      "score 0.10428776725216349\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11099921483412137\n",
      "score 0.10411943064699715\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6604764638334212\n",
      "score 0.48424140171646374\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6545312410188002\n",
      "score 0.4802743364973444\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6432572134709669\n",
      "score 0.4553916412699473\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5720307817502396\n",
      "score 0.36846979718593825\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39632821402515084\n",
      "score 0.2228827179706662\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.15208360053032002\n",
      "score 0.1034283060941818\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11777723866084236\n",
      "score 0.08768794626263246\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11559872634275015\n",
      "score 0.08667744672984075\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6521647870042709\n",
      "score 0.5298101442600237\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6584030375277399\n",
      "score 0.5256069021794467\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.631920514607672\n",
      "score 0.509409164135575\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5562624971160469\n",
      "score 0.4341072920305783\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3723337219602136\n",
      "score 0.32177157585009214\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.14054223318393333\n",
      "score 0.12794095521086146\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11340980185279476\n",
      "score 0.10424734985479642\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11157480479015464\n",
      "score 0.10268867711626763\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.60308213523413\n",
      "score 0.7119284475460775\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.627238836817692\n",
      "score 0.6354554903963243\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6121967930629009\n",
      "score 0.6166405950199815\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5244951856970984\n",
      "score 0.5812148395757716\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.32811929490202574\n",
      "score 0.4544578522847884\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12948161653166407\n",
      "score 0.1463495390899236\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11022669966862203\n",
      "score 0.11566528438771356\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10884115175022938\n",
      "score 0.11349921932183027\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6050441439090781\n",
      "score 0.7095533515644383\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5978793539240151\n",
      "score 0.7097552052235985\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5789309703860128\n",
      "score 0.6925982553757182\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5112681505438188\n",
      "score 0.5910690355155377\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3537924427224405\n",
      "score 0.36503809291444\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.13082287435537143\n",
      "score 0.16726114597699593\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10359251244379394\n",
      "score 0.14335438044430576\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10180589213570856\n",
      "score 0.1417471874143796\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.6186293411814352\n",
      "score 0.6506825945076529\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.62746660959685\n",
      "score 0.6440974230483846\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.5981345191710622\n",
      "score 0.6398384266493631\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.520521968912627\n",
      "score 0.5943689303755851\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.34250204608529244\n",
      "score 0.39764352960362565\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1355553048227954\n",
      "score 0.1345567775803423\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11272765491184206\n",
      "score 0.10625751233823011\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11115236178219014\n",
      "score 0.1043103969185408\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4459515876960882\n",
      "score 0.22348401747346885\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.44594527859402683\n",
      "score 0.2234827942284373\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4458708196120769\n",
      "score 0.22344558362021355\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.44527530993072006\n",
      "score 0.22318498533221193\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4407642121640299\n",
      "score 0.2212269647976003\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4088803522222431\n",
      "score 0.2076685940996873\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1954168279068552\n",
      "score 0.120538772040557\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11958584882255624\n",
      "score 0.0885382604150544\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4142989555712928\n",
      "score 0.35007931061333775\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.41429570562861484\n",
      "score 0.3500771553963038\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4142203102139888\n",
      "score 0.3500192618030486\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4136302645771255\n",
      "score 0.34954775072547234\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.40916257965684066\n",
      "score 0.345933251200116\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3776448240823416\n",
      "score 0.3201742864718139\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1748355586581003\n",
      "score 0.153618837032404\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11503833255468475\n",
      "score 0.10537651236807469\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36121451887910505\n",
      "score 0.562425117829142\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36120507036842675\n",
      "score 0.5624043642370374\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36113065078619727\n",
      "score 0.5622766837743958\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36055009507430763\n",
      "score 0.5612415112391974\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.35620827049118237\n",
      "score 0.5535118371437495\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.32556649555166123\n",
      "score 0.498864220048551\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1484349182107766\n",
      "score 0.18114016961047885\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11132203524790833\n",
      "score 0.11752088447592096\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3972617473928495\n",
      "score 0.41823795924147267\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39725853063229044\n",
      "score 0.4182341670137236\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3971770082033895\n",
      "score 0.4181649561739926\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39658745800689077\n",
      "score 0.41761531937120444\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3921427505122028\n",
      "score 0.4135132745971028\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.360736453305848\n",
      "score 0.3844477856886135\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.16073716830159096\n",
      "score 0.19748016904549234\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.1049860601906828\n",
      "score 0.14482991263209935\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.38855536744666963\n",
      "score 0.4530508480676434\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3885516641172383\n",
      "score 0.4530445530373779\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3884714688440526\n",
      "score 0.452946916927592\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3878885813847545\n",
      "score 0.4521898416241415\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3834915561143242\n",
      "score 0.4465750066536122\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.35244362923662215\n",
      "score 0.40722977720253545\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.16155054287259685\n",
      "score 0.16624621751940516\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11408529204966003\n",
      "score 0.10779612498849132\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "(210, 42)\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4459500660205502\n",
      "score 0.22348339386688704\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4459500660205502\n",
      "score 0.22348339386688704\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.44587721751727183\n",
      "score 0.22345065156139554\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.445329426704208\n",
      "score 0.22322943483114166\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.44115422356409023\n",
      "score 0.2215292764416083\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4116657937154309\n",
      "score 0.20949665295816633\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.20866364333583481\n",
      "score 0.12667374293843434\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.12006716397870171\n",
      "score 0.08881733861023508\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4143017881624785\n",
      "score 0.3500792395161815\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.4142995073774448\n",
      "score 0.35007730153798255\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.41422576496765506\n",
      "score 0.3500162629854937\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.41368567938174156\n",
      "score 0.3495738174857664\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.40956402637678346\n",
      "score 0.34619386232578353\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.38049732462069985\n",
      "score 0.32236819820560486\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.18584526113328043\n",
      "score 0.16282931214961124\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11545797450994937\n",
      "score 0.10574666990597156\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3612114738159191\n",
      "score 0.5624196562326478\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36120808790352765\n",
      "score 0.5624126859599318\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.36113722331807785\n",
      "score 0.5622883956608856\n",
      "(168, 6)\n",
      "(211, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score0 0.3606097410062051\n",
      "score 0.5613375391952614\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.35659671394840203\n",
      "score 0.5541195129032266\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3283484932769597\n",
      "score 0.5033856026279437\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.15523084591509753\n",
      "score 0.19276698860819366\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11164577519658936\n",
      "score 0.11801345535546867\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3972607356195228\n",
      "score 0.41823785360512017\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3972585610509419\n",
      "score 0.4182355436084012\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3971889028874397\n",
      "score 0.4181748775881799\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.396648034442802\n",
      "score 0.41766552262096823\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.39253841105612397\n",
      "score 0.4138270728455681\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.363568491197403\n",
      "score 0.3867385713965819\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.17131226422761484\n",
      "score 0.20694876361720982\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.10540771933408649\n",
      "score 0.14519309125381058\n",
      "5\n",
      "4\n",
      "1\n",
      "(168, 210)\n",
      "(168, 211)\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3885570455560412\n",
      "score 0.45305581540022677\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3885540002848692\n",
      "score 0.4530514078120117\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.38849141184368774\n",
      "score 0.45297370322013086\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3879489683249601\n",
      "score 0.45228590185200923\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.3838816851017538\n",
      "score 0.44713469653452587\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.35520773797041594\n",
      "score 0.4108593078346915\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.17030289959196115\n",
      "score 0.177030961428772\n",
      "(168, 6)\n",
      "(211, 6)\n",
      "score0 0.11446657928615778\n",
      "score 0.10821946243489258\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-0c716661f9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/cs_ope/cs_ope/cs_opl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, folds, num_basis, sigma_list, lda_list, algorithm, logit)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_chosen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_chosen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "estimators.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pi_behavior_seq_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_regression import KernelReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Y_matrix, train_test_split, x_prob, classes, N, N_train, N_test = data_generation(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.01, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KernelRidge(alpha=0.01)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(penalty='l1', C=0.1, solver='saga', multi_class='multi_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.where(Y_matrix == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 159660 into shape (4435,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ffa7af881c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kernel_regression.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, var_type, reg_type, bw, defaults)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_adjust_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_adjust_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/_kernel_base.py\u001b[0m in \u001b[0;36m_adjust_shape\u001b[0;34m(dat, k_vars)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ndim >1 so many obs many vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 159660 into shape (4435,1)"
     ]
    }
   ],
   "source": [
    "model = KernelReg([1,100,1], X, var_type='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'3'*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cccccccccccccccccccccccccccccccccccc'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c'*X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_u = sm.nonparametric.KDEMultivariate(data=X, var_type='c'*dim, bw='normal_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.56532044)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dens_u.pdf(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = dens_u.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[:50]\n",
    "X = X[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_u = sm.nonparametric.KDEMultivariate(data=X, var_type='c'*X.shape[1], bw='normal_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelReg(Y, X, var_type='c'*X.shape[1], reg_type='lc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19174831, 0.28450028, 0.27009914, 0.15901443, 0.30847048,\n",
       "       0.28977343, 0.17193598, 0.03891559, 0.20149673, 0.31748389,\n",
       "       0.28018324, 0.28895554, 0.15374873, 0.21203015, 0.57902868,\n",
       "       0.05410153])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, x = model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119904"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.73930242, 4.83120944, 4.76830902, 4.05162109, 4.54722321,\n",
       "        4.90765989, 4.45411434, 4.89109568, 4.71458883, 4.78442258,\n",
       "        4.7987667 , 4.75148552, 4.46570638, 4.97899378, 4.98634629,\n",
       "        4.81090934]),\n",
       " array([[-2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15],\n",
       "        [-1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16],\n",
       "        [-1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16],\n",
       "        [-1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16],\n",
       "        [-1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16],\n",
       "        [-1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16],\n",
       "        [-4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15],\n",
       "        [-6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15],\n",
       "        [ 1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16],\n",
       "        [-9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14],\n",
       "        [-2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16],\n",
       "        [-1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16],\n",
       "        [-2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16],\n",
       "        [-2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15],\n",
       "        [-4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15],\n",
       "        [-1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[-16:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 36)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([[-99.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2857443  0.1952922  0.26814298 0.07805563 0.05606263 0.11670226]\n",
      " [0.29536795 0.15428734 0.27987302 0.0802635  0.05640643 0.13380176]\n",
      " [0.37533892 0.1459109  0.18370155 0.12563121 0.06332002 0.10609741]\n",
      " ...\n",
      " [0.20679231 0.16011928 0.29419599 0.0838981  0.1119685  0.14302582]\n",
      " [0.31595816 0.13683452 0.25687274 0.10179922 0.11506038 0.07347497]\n",
      " [0.28837575 0.1668954  0.27622361 0.06731022 0.08418668 0.11700835]]\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08136092229213432, tolerance: 0.04414618372652263\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08136092229213432, tolerance: 0.04414618372652263\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09048368117350947, tolerance: 0.04430395631018423\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09048368117350947, tolerance: 0.04430395631018423\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08161668621410456, tolerance: 0.04447331896825037\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08161668621410456, tolerance: 0.04447331896825037\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00056\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00006\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 31.56571\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.17952\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.35085\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.38121\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.45369\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06027\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00623\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00062\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 2105.09781\n",
      "sigma = 10.00000, lambda = 0.01000, score = 410.15885\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.66124\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.53089\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52516\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37793\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08145\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00911\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.09672\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.46082\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49609\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.47\n",
      "Approximate alpha-relative KL-divergence = 1.38\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00073\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00007\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 33.96512\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.36617\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.53581\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.51109\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47588\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06146\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00633\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00063\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1656.12344\n",
      "sigma = 10.00000, lambda = 0.01000, score = 390.18081\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.43140\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52032\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52560\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37866\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08175\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00914\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 18.40631\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45219\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50032\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49609\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.46\n",
      "Approximate alpha-relative KL-divergence = 1.39\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03031991178854554, tolerance: 0.02230264291344382\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03031991178854554, tolerance: 0.02230264291344382\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043619514194688236, tolerance: 0.022751581831235764\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043619514194688236, tolerance: 0.022751581831235764\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00072\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00007\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 28.91635\n",
      "sigma = 1.00000, lambda = 0.01000, score = -0.78712\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.22179\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.30595\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42709\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05663\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00585\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00059\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1701.65429\n",
      "sigma = 10.00000, lambda = 0.01000, score = 430.16227\n",
      "sigma = 10.00000, lambda = 0.10000, score = 14.54468\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.50482\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52391\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37739\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08152\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00912\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 28.82476\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.42002\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50030\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50020\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49601\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.95\n",
      "Approximate alpha-relative KL-divergence = 1.31\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0439595261181438, tolerance: 0.02206473411299383\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0439595261181438, tolerance: 0.02206473411299383\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03466387270604798, tolerance: 0.022250593846881925\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03466387270604798, tolerance: 0.022250593846881925\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04257241943840029, tolerance: 0.02164541446099271\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04257241943840029, tolerance: 0.02164541446099271\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02999003355433416, tolerance: 0.021463531141462978\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02999003355433416, tolerance: 0.021463531141462978\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029693701291321872, tolerance: 0.02147754261963311\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029693701291321872, tolerance: 0.02147754261963311\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00108\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00011\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 59.50772\n",
      "sigma = 1.00000, lambda = 0.01000, score = -2.21544\n",
      "sigma = 1.00000, lambda = 0.10000, score = -3.19060\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.54425\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.43621\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05483\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00563\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00056\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1845.37172\n",
      "sigma = 10.00000, lambda = 0.01000, score = 362.72388\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.63708\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.50617\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52621\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37752\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08130\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00909\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 23.92714\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.42282\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50033\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49603\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.86\n",
      "Approximate alpha-relative KL-divergence = 1.42\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00102\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00010\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 48.74342\n",
      "sigma = 1.00000, lambda = 0.01000, score = 1.12235\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.43478\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.49822\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47382\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06167\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00636\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00064\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1999.37845\n",
      "sigma = 10.00000, lambda = 0.01000, score = 430.62733\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.26423\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52086\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52619\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37945\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08199\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00917\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 21.90755\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.44597\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50032\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49604\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37487\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.33\n",
      "Approximate alpha-relative KL-divergence = 1.38\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00078\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00008\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 46.87919\n",
      "sigma = 1.00000, lambda = 0.01000, score = -2.06557\n",
      "sigma = 1.00000, lambda = 0.10000, score = -3.14872\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.50040\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42257\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05335\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00548\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00055\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 2182.46624\n",
      "sigma = 10.00000, lambda = 0.01000, score = 422.24404\n",
      "sigma = 10.00000, lambda = 0.10000, score = 11.09138\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52940\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52442\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37777\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08164\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00913\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.36423\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45932\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50022\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.61\n",
      "Approximate alpha-relative KL-divergence = 1.36\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00149\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00015\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 62.54142\n",
      "sigma = 1.00000, lambda = 0.01000, score = 1.22332\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.16187\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.36914\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47048\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06229\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00643\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00065\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10.00000, lambda = 0.00100, score = 1963.16851\n",
      "sigma = 10.00000, lambda = 0.01000, score = 365.56594\n",
      "sigma = 10.00000, lambda = 0.10000, score = 8.20643\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52881\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52418\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37816\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08173\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00914\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 14.14147\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.47064\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50030\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50022\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.28\n",
      "Approximate alpha-relative KL-divergence = 1.29\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039658722675653735, tolerance: 0.022165703298471957\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039658722675653735, tolerance: 0.022165703298471957\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.054870372145039426, tolerance: 0.02237794960418357\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.054870372145039426, tolerance: 0.02237794960418357\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03902818322756474, tolerance: 0.022544226827337432\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03902818322756474, tolerance: 0.022544226827337432\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045200808209827414, tolerance: 0.022670570996965463\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045200808209827414, tolerance: 0.022670570996965463\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00171\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00017\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00002\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 38.73322\n",
      "sigma = 1.00000, lambda = 0.01000, score = 0.12444\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.39572\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.43401\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.45452\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05947\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00613\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00062\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1964.32896\n",
      "sigma = 10.00000, lambda = 0.01000, score = 405.38895\n",
      "sigma = 10.00000, lambda = 0.10000, score = 9.64578\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52058\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52197\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37624\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08127\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00909\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 16.28299\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.46219\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50028\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50019\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49600\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37483\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.78\n",
      "Approximate alpha-relative KL-divergence = 1.32\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00112\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00011\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 53.07018\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.44841\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.55276\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.38294\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42864\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05575\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00575\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00058\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1509.89988\n",
      "sigma = 10.00000, lambda = 0.01000, score = 398.00889\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.57141\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.51076\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52433\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37657\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08112\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00907\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 23.10916\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.43039\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50021\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37484\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.00\n",
      "Approximate alpha-relative KL-divergence = 1.30\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00116\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00012\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 50.76982\n",
      "sigma = 1.00000, lambda = 0.01000, score = -0.50875\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.48143\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.45807\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.43598\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05504\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00565\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00057\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1788.29679\n",
      "sigma = 10.00000, lambda = 0.01000, score = 340.14796\n",
      "sigma = 10.00000, lambda = 0.10000, score = 11.03595\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.51514\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52476\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37761\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08142\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00910\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.66439\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.44420\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50021\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.28\n",
      "Approximate alpha-relative KL-divergence = 1.42\n",
      "RuLSIF completed.\n",
      "0.0020615203965287134\n",
      "0.13496492396029341\n",
      "0.14052462440146124\n",
      "0.14454640025621163\n",
      "0.07316521953909505\n",
      "0.06772742895011623\n",
      "[[0.24102912 0.06764163 0.17187361 0.10285628 0.10133621 0.31526315]\n",
      " [0.22805161 0.16242707 0.24136784 0.13808953 0.09609416 0.1339698 ]\n",
      " [0.4419999  0.12967623 0.16618194 0.09248787 0.09328026 0.07637381]\n",
      " ...\n",
      " [0.22448224 0.16734621 0.23944092 0.13555183 0.10691164 0.12626715]\n",
      " [0.19431824 0.25503681 0.19142227 0.14680791 0.12565408 0.08676068]\n",
      " [0.22133478 0.12516184 0.21841313 0.15798502 0.12293443 0.15417081]]\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07433223137628175, tolerance: 0.040998332075193954\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07433223137628175, tolerance: 0.040998332075193954\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00051\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00005\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 23.52820\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.91904\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.53857\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.35261\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.39886\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05087\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00523\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00052\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1886.07764\n",
      "sigma = 10.00000, lambda = 0.01000, score = 402.87575\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.98566\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52797\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52472\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37652\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08091\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00904\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00091\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.85918\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45462\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49608\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37493\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.99\n",
      "Approximate alpha-relative KL-divergence = 1.29\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00042\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00004\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 28.70297\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.56904\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.85820\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.51123\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.40226\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.04921\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00503\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00050\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1973.13400\n",
      "sigma = 10.00000, lambda = 0.01000, score = 458.17791\n",
      "sigma = 10.00000, lambda = 0.10000, score = 13.48332\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52377\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52774\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37798\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08104\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00905\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 24.85998\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.43675\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50034\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50026\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49611\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-afe327fa7d7e>\", line 45, in <module>\n",
      "    res_dr2 = dr(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Ridge')\n",
      "  File \"../cs_ope_estimator.py\", line 79, in dr\n",
      "    densratio_obj = densratio(X_evl, X_hst)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/core.py\", line 66, in densratio\n",
      "    result = RuLSIF(x, y, alpha, sigma_range, lambda_range, kernel_num, verbose)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 61, in RuLSIF\n",
      "    opt_params = search_sigma_and_lambda(x, y, alpha, centers, sigma_range, lambda_range, verbose)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 152, in search_sigma_and_lambda\n",
      "    phi_y = compute_kernel_Gaussian(y, centers, sigma)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in compute_kernel_Gaussian\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in <listcomp>\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in <listcomp>\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 194, in kernel_Gaussian\n",
      "    return exp(- (norm(x - y) ** 2) / (2 * sigma * sigma))\n",
      "  File \"<__array_function__ internals>\", line 6, in norm\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\", line 2483, in norm\n",
      "    ret = sqrt(sqnorm)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/posixpath.py\", line 366, in normpath\n",
      "    new_comps.append(comp)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "num_trials = 100\n",
    "alphas = [0.7, 0.4, 0.0]\n",
    "\n",
    "tau_list = np.zeros(num_trials)\n",
    "res_ipw3_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dm_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml1_truew_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml2_truew_list = np.zeros((num_trials, len(alphas)))\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    X, Y, Y_matrix, train_test_split, x_prob, classes, N, N_train, N_test = data_generation(data_name)\n",
    "\n",
    "    X_train, X_test = X[train_test_split], X[~train_test_split]\n",
    "    Y_train, Y_test = Y[train_test_split], Y[~train_test_split]\n",
    "    Y_matrix_train, Y_matrix_test = Y_matrix[train_test_split], Y_matrix[~train_test_split]\n",
    "\n",
    "    pi_behavior, pi_evaluation  = behavior_and_evaluation_policy(X, Y, train_test_split, classes, alpha=0.7)\n",
    "\n",
    "    pi_behavior_train, pi_behavior_test = pi_behavior[train_test_split], pi_behavior[~train_test_split]\n",
    "    pi_evaluation_train, pi_evaluation_test = pi_evaluation[train_test_split], pi_evaluation[~train_test_split]\n",
    "\n",
    "    tau = true_value(Y_matrix_test, pi_evaluation_test, N_test)\n",
    "\n",
    "    for idx_alpha in  range(len(alphas)):    \n",
    "        alpha = alphas[idx_alpha]\n",
    "        pi_behavior, pi_evaluation  = behavior_and_evaluation_policy(X, Y, train_test_split, classes, alpha=alpha)\n",
    "\n",
    "        perm = np.random.permutation(N_train)\n",
    "\n",
    "        X_seq_train, Y_matrix_seq_train, pi_behavior_seq_train, pi_evaluation_seq_train = X_train[perm], Y_matrix_train[perm], pi_behavior_train[perm], pi_evaluation_train[perm]\n",
    "\n",
    "        Y_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "        A_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "\n",
    "        for i in range(N_train):\n",
    "            a = np.random.choice(classes, p=pi_behavior[i])\n",
    "            Y_historical_matrix[i, a] = 1\n",
    "            A_historical_matrix[i, a] = 1\n",
    "            \n",
    "        #IPW3 estimator\n",
    "        res_ipw3 = ipw(Y_historical_matrix, X_seq_train, X_test, classes, pi_evaluation_train, A_hst=A_historical_matrix)\n",
    "        #Direct method estimator\n",
    "        res_dm = dm(Y_historical_matrix, X_seq_train, X_test, pi_evaluation_test, classes)\n",
    "        #DML with L1\n",
    "        res_dml1 =dml(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Lasso')\n",
    "        #DML with L2\n",
    "        res_dml2 =dml(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Ridge')\n",
    "\n",
    "        print(res_ipw3)\n",
    "        print(res_dm)\n",
    "        print(res_dr1)\n",
    "        print(res_dr2)\n",
    "        print(res_dml1_truew)\n",
    "        print(res_dml2_truew)\n",
    "        \n",
    "        res_ipw3_list[trial, idx_alpha] = res_ipw3\n",
    "        res_dm_list[trial, idx_alpha] = res_dm\n",
    "        res_dr1_list[trial, idx_alpha] = res_dr1\n",
    "        res_dr2_list[trial, idx_alpha] = res_dr2\n",
    "        res_dml1_truew_list[trial, idx_alpha] = res_dml1_truew\n",
    "        res_dml2_truew_list[trial, idx_alpha] = res_dml2_truew\n",
    "        \n",
    "        np.savetxt(\"exp_results/res_ipw3.csv\", res_ipw3_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dm.csv\", res_dm_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dr1.csv\", res_dr1_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dr2.csv\", res_dr2_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dml1.csv\", res_dml1_truew_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dml2.csv\", res_dml2_truew_list, delimiter=\",\")\n",
    "        \n",
    "    tau_list[trial] = tau\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
